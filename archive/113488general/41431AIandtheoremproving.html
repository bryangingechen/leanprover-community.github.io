---
layout: page
title: Lean Prover Zulip Chat Archive 
permalink: archive/113488general/41431AIandtheoremproving.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/113488general/index.html">general</a>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html">AI and theorem proving</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com">
{% raw %}
<a name="166042079"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042079" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042079">Jason Rute (May 19 2019 at 21:53)</a>:</h4>
<p>First, since I’ve only posted a few times in here, I thought I’d introduce myself.  I’m a former mathematician turned data scientist.  I used to work on computability theory and algorithmic randomness.  Jeremy Avigad was my advisor, which makes me an academic sibling to a couple of you.  Before graduate school, I worked on the Flyspeck project for a bit, but then lost interest in interactive theorem proving.  I’ve become more interested in it again with Lean and with the many advancements in AI and theorem proving.  </p>
<p>I’m especially interested in AI for theorem proving and I closely follow the field (as an outsider). I’m always happy to chat about it.  Since there have been many discussions here on the topic and I’d thought I’d share some resources and thoughts I have.  (Disclaimer: I am only an interested outsider.  I am not involved in any way with this research.)</p>

<a name="166042082"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042082" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042082">Jason Rute (May 19 2019 at 21:53)</a>:</h4>
<p><a href="https://slideslive.com/38909911/no-one-shall-drive-us-from-the-semantic-ai-paradise-of-computerunderstandable-math-and-science" target="_blank" title="https://slideslive.com/38909911/no-one-shall-drive-us-from-the-semantic-ai-paradise-of-computerunderstandable-math-and-science">This talk</a> by Joseph Urban is a great introduction to the state of field.  For more in depth, here are two <a href="http://phdopen.mimuw.edu.pl/index.php?page=z18w2" target="_blank" title="http://phdopen.mimuw.edu.pl/index.php?page=z18w2">sets of</a> <a href="http://cl-informatik.uibk.ac.at/teaching/ss18/mltp/content.php" target="_blank" title="http://cl-informatik.uibk.ac.at/teaching/ss18/mltp/content.php">lectures</a> on the subject by Cezary Kaliszyk.  (The first is just three lectures and has videos.)  Indeed, these two people and their respective labs seem to be leading the charge in AI for theorem proving.</p>
<p>Recently Berkeley, OpenAI, Google AI, and DeepMind are also getting into the field, which is really exciting.  Berkeley and OpenAI released <a href="https://github.com/ml4tp/gamepad" target="_blank" title="https://github.com/ml4tp/gamepad">GamePad</a> which is a learning environment to train AI agents in Coq.  Google AI just released a similar learning environment <a href="https://sites.google.com/view/holist/home" target="_blank" title="https://sites.google.com/view/holist/home">HOList</a> for HOL-Light (see slides at <a href="http://aitp-conference.org/2019/" target="_blank" title="http://aitp-conference.org/2019/">AITP 2019</a>).  Both of these projects provide datasets (e.g. the Flyspeck library) and some weak baselines.  As for DeepMind, Demis Hassabis recently mentioned “theorem proving” as one of the science projects they are working on right now (search “theorem” in <a href="https://cbmm.mit.edu/video/power-self-learning-systems" target="_blank" title="https://cbmm.mit.edu/video/power-self-learning-systems">this video/transcript</a>).</p>
<p>As for tactic-based ITPs, besides GamePad and HOList, there is <a href="https://github.com/HOL-Theorem-Prover/HOL/tree/master/src/tactictoe" target="_blank" title="https://github.com/HOL-Theorem-Prover/HOL/tree/master/src/tactictoe">TacticToe</a>, which is probably the most useful of the tools so far.  It fills in tactic proofs for HOL4 (<a href="https://arxiv.org/abs/1804.00596" target="_blank" title="https://arxiv.org/abs/1804.00596">paper</a>, slides/video at <a href="http://aitp-conference.org/2018/" target="_blank" title="http://aitp-conference.org/2018/">AITP 2018</a>).  Also, there appears to be <a href="https://github.com/data61/PSL" target="_blank" title="https://github.com/data61/PSL">PSL</a> for Isabelle, but I don't know much about it.</p>
<p>In another channel someone asked about using AlphaZero (or AlphaGo Zero) methods for theorem proving.  Despite what most people think, the AlphaZero algorithm isn’t so much about playing games as training an agent to search through a tree.  Historically, tree search algorithms in games used min-max with alpha-beta pruning.  That is they use a depth-first search to a certain level of depth, hand written heuristics, heavy pruning, and other optimizations—very similar to the tree searches methods in ATPs.  In contrast, Monte Carlo Tree Search (MCTS) explores paths through the tree “at random” (formally it uses UCBT and random rollouts) avoiding the need for hand-written heuristics.  The AlphaZero variant of MCTS eliminates the need to explore to the end of the tree, instead using policy and value heuristics learned by a neural network to guide the search towards nodes in the tree that look “valuable”.  Eliminating the need to explore to the end makes AlphaZero MCTS useful in other tree and graph search problems with sparse terminal states, such as theorem proving.  Indeed, most theorem proving settings can be thought of as tree search problems.  The nodes in the tree are partially constructed proofs and edges are manipulations which lead to the new partial proof.  For example, in tactic-based ITPs, the nodes correspond to a sets of open goals and the edges correspond to tactics which can be applied to the goals.  In other settings, the nodes are are partially built proof trees or tableaus and the edges correspond to inference rules (in say a cut-free sequent calculus).  Many papers in AI and theorem proving are starting to experiment with MCTS.  For example, the TacticToe paper (the most recent version) uses MCTS, but with hand-engineered heuristics.</p>
<p>Another important trend in theorem proving is reinforcement learning (RL), that is learning by exploring the space instead of using labeled data.  This is important since as many have stated there isn’t a lot of human labeled data to use in theorem proving.  Recently, there have been some successful experiments in this area: <a href="https://arxiv.org/abs/1805.07563" target="_blank" title="https://arxiv.org/abs/1805.07563">rlCOP</a> (slides/video at <a href="http://aitp-conference.org/2018/" target="_blank" title="http://aitp-conference.org/2018/">AITP 2018</a>), <a href="https://arxiv.org/abs/1807.08058" target="_blank" title="https://arxiv.org/abs/1807.08058">an RL-trained QBF solver</a>, and <a href="https://arxiv.org/abs/1811.00796v1" target="_blank" title="https://arxiv.org/abs/1811.00796v1">an RL-trained intuitionistic theorem prover</a>.  These results are really encouraging and many of these systems use MCTS and other ideas borrowed from AlphaZero.  Nonetheless, the systems are still quite limited.</p>
<p>There are also applications of AI/ML to SMT solvers, SAT solvers, QBF solvers, resolution theorem provers, connection-style theorem provers, and a variety of different logics.  While there aren’t a lot of researchers directly working on theorem proving, there a number of related research topics including program synthesis, question answering and reasoning in natural language, theorem proving in large relational knowledge databases, and neural-symbolic learning.</p>

<a name="166042086"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042086" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042086">Jason Rute (May 19 2019 at 21:54)</a>:</h4>
<p>I’d also like to share some major trends and challenges I’ve seen in the area of AI for theorem proving.  </p>
<p>Suppose an agent wants to prove a theorem or fill in a gap in a proof.  It could prove it from scratch, but it is much easier to use previously proved facts.  However, if we have a long list of previously proved facts, our combinatorial search space will grow considerably.  This is called the “premise selection problem”.  (For some tactics one also has to specify terms as arguments.  This again is a sort of premise selection problem.)</p>
<p>More powerfully, one would like an agent which creates its own definitions and lemmas.  (This is akin to the difference between a proof system with and without cut, the former allowing arbitrary lemmas.)  All the current benchmarks I am aware of use theorem proving libraries where the intermediate lemmas are already given (or can be chosen from a large list of previously proved results).  I know of no system which has the ability to make its own definitions or lemmas.  (Although in the related field of program synthesis there is work on automatic creation of reusable subroutines.)</p>
<p>Another major trend is feature extraction.  In order to do machine learning on formulas, one has to extract the useful information from the formula.  One time honored tradition is manual “feature engineering”.  While neural networks are really good at automatically discovering features, many of the most successful current systems (e.g. TacticToe) still don’t use neural networks since they are too slow.  Instead they use hand-engineered features in conjunction with faster machine learning methods like boosted trees or nearest-neighbor search.  Nonetheless, I think in the end neural networks will win.  It is already established that neural networks allow one to significantly decrease the search space in many theorem proving tasks, and as we build systems that are more ambitious this exponential speedup in search space will outpace the linear slowdown in feature computation.  While tools like SMT solvers are massively optimized, they only work well in narrow domains.  For research math problems, we need an agent which can learn from the cutting edge without hand engineering.  And we would be willing to wait an hour to solve a problem that would take a week or more for a human to solve.</p>
<p>Even if one uses neural networks to extract features from terms (or formulas, goals, etc.), there are a number of design choices.  While terms (and formulas, etc.) are just strings of symbols, neural networks which are designed for strings of symbols (1D CNNs and LSTMs) don’t seem to work as well.  The reason is that that terms have a deep recursive tree-based structure.  There has been more success with recursive tree neural networks which better capture this recursive structure.  However, formulas aren’t really well represented as trees either because they have bound variables with arbitrary names.  Instead, it seems to be best to use DeBruijn representations where each bound variable is connected to the associated quantifier.  Graph neural networks are amenable to this representation of a term (or formula, etc) as a graph, and seem to do empirically better.  However graph neural networks are still a new concept and more experimentation is likely needed.</p>
<p>Despite all the areas for improvement, I am very hopeful.  I have no doubt that theorem proving is difficult, but incremental progress can have tangible value: Speeding up SMT and SAT solvers.  Learning to quickly prove basic facts in new domains.  Improving the tactics in ITPs to fill in the “obvious parts”.  Improving hardware and software formalization.  Speeding up compilers (even the Lean compiler/type-checker).  This will likely come before automatically proving Math Olympiad problems, auto-formalizing arXiv, having a computer develop new areas of mathematics, or solving really hard research problems.</p>
<p>Another reason to be hopeful is that the tools being built in AI are amazingly general.  For example, two of the important tools used in AlphaStar (DeepMind’s recent Starcraft II AI) are transformers and LSTMs.  Both of these were developed for sequence-to-sequence learning such as machine translation.  Nonetheless, they also turned out to be very applicable to playing real-time strategy games and a host of other problems such as creating computer generated images.  This reusability of tools is a big win.  Researchers don’t need to be working on theorem proving in particular to develop ideas, such as MCTS and graph neural networks, which can be repurposed for theorem proving.  Indeed the problems plaguing AI and theorem proving, such as an infinite search space, are also problems in many other areas of AI.  (Just search for “the bigger picture” in <a href="https://cbmm.mit.edu/video/power-self-learning-systems" target="_blank" title="https://cbmm.mit.edu/video/power-self-learning-systems">this DeepMind talk</a>).  Moreover, I think many of the advanced ideas in AI haven’t even been tried in theorem proving (neither the HOList nor GamePad baselines use graph neural networks for example), which is why I am very excited that the big players (e.g. DeepMind) are joining the field since they have a lot of experience and have shown a willingness to tackle ambitious projects.  Now we just need to convince them that this is worth the payoff!</p>
<p>And finally it seems that, by using reinforcement learning and lots of computer power, we can quickly scale up from ok progress on an AI task to great progress.  Thinking big (maybe too big), if we can teach an AI agent how to make definitions and lemmas, how to use curiosity to explore a new mathematical subject, and how to effectively leverage previous proved knowledge to build new knowledge, then we might—just might—get really impressive results…</p>

<a name="166042146"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042146" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042146">Jason Rute (May 19 2019 at 21:55)</a>:</h4>
<p>(Sorry for the long posts.  As Jeremy can attest to, I haven't learned the skill of short writing.)</p>

<a name="166042194"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042194" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042194">Jason Rute (May 19 2019 at 21:56)</a>:</h4>
<p>(Also, I know many of these resources have been shared many times.  I thought there was value in putting them together in the same place.)</p>

<a name="166042216"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042216" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042216">Kevin Buzzard (May 19 2019 at 21:57)</a>:</h4>
<p>Thanks a lot for these -- I find myself a few times a week on an exercise machine and it's great to have stuff to watch there -- I still haven't figured out how to do Lean whilst pedalling energetically.</p>

<a name="166042393"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042393" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042393">Kevin Buzzard (May 19 2019 at 22:01)</a>:</h4>
<p>Making mathematical definitions is an art -- it's analogous to making new tools. Getting computers to prove theorems using a given set of tools sounds like a much easier problem, and even that seems very difficult to do at the minute.</p>

<a name="166042445"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042445" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042445">Kevin Buzzard (May 19 2019 at 22:02)</a>:</h4>
<p>Brian Conrad is fond of challenging me to get my computer to invent / discover a proof that there are infinitely many primes, and even given the fact that the integers are a unique factorization domain I think a computer would find this hard to do.</p>

<a name="166042891"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042891" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042891">Jason Rute (May 19 2019 at 22:15)</a>:</h4>
<p>I agree discovering definitions and "interesting" results will be one of the last things we figure out how to do well.  As far as making new tools, I think to scale automatic theorem proving, we will have to figure out how to build new tactics or make simple lemmas that factor out common proof steps.  This is related to other problems in AI such as hierarchical reinforcement learning where one wants to learn new high level actions made up of low level actions.  Theorem proving is interesting in that the ability to package small steps into one big step is built into the theorem proving framework already, but it is not clear how one would take advantage of it.</p>

<a name="166043229"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166043229" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166043229">Jason Rute (May 19 2019 at 22:24)</a>:</h4>
<p>But speaking of hierarchical RL, the <a href="https://openai.com/blog/openai-five/" target="_blank" title="https://openai.com/blog/openai-five/">OpenAI Five</a> Dota AI is an interesting example.  They thought they would have to solve hierarchical reinforcement learning before they could solve Dota, but it turns out the existing tools (namely LSTMs) already were capable of learning complicated strategies which are executed over a very long time period.  So maybe lemmas and hierarchical RL is not as important as I think.</p>

<a name="166043629"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166043629" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166043629">Moses Schönfinkel (May 19 2019 at 22:36)</a>:</h4>
<p>And yet it didn't even learn the neutral-camp pull into lane! ;) Thanks for the write-up.</p>


{% endraw %}
